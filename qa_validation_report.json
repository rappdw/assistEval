{
  "summary": {
    "timestamp": "2025-08-29T11:58:45.716039",
    "total_duration": 16.144724,
    "categories_tested": 2,
    "overall_status": "critical_failure",
    "test_summary": {
      "total_tests": 23,
      "total_failures": 5,
      "success_rate": 78.26086956521739,
      "categories_passed": 0,
      "categories_failed": 2
    },
    "performance_metrics": {
      "total_execution_time": 14.64,
      "average_category_time": 7.32,
      "slowest_category": "integration",
      "performance_threshold_met": false
    },
    "recommendations": [
      "Address failures in: statistical_accuracy, integration",
      "Optimize performance for: statistical_accuracy, integration"
    ]
  },
  "detailed_results": {
    "statistical_accuracy": {
      "status": "failed",
      "exit_code": 1,
      "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.12.6, pytest-8.4.1, pluggy-1.6.0 -- /Users/drapp/dev/assistEval/.venv/bin/python\ncachedir: .pytest_cache\nrootdir: /Users/drapp/dev/assistEval\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, cov-6.2.1\ncollecting ... collected 10 items\n\ntests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_compare_providers_ttest PASSED [ 10%]\ntests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_compare_providers_mannwhitney PASSED [ 20%]\ntests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_compare_providers_auto_selection PASSED [ 30%]\ntests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_effect_size_calculation PASSED [ 40%]\ntests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_basic_functionality PASSED [ 50%]\ntests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_empty_data_handling FAILED [ 60%]\ntests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_single_value_data PASSED [ 70%]\ntests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_identical_data FAILED [ 80%]\ntests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_statistical_result_properties PASSED [ 90%]\ntests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_significance_threshold PASSED [100%]\n\n=================================== FAILURES ===================================\n_______________ TestStatisticalAnalyzer.test_empty_data_handling _______________\ntests/test_analytics_statistics.py:95: in test_empty_data_handling\n    self.analyzer.compare_providers([], self.normal_data_b)\nbench/analytics/statistics.py:54: in compare_providers\n    assumptions = self._check_assumptions(a_scores, b_scores)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nbench/analytics/statistics.py:205: in _check_assumptions\n    _, p_a = stats.shapiro(group_a)\n             ^^^^^^^^^^^^^^^^^^^^^^\n.venv/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:574: in axis_nan_policy_wrapper\n    warnings.warn(too_small_msg, SmallSampleWarning, stacklevel=2)\nE   scipy.stats._axis_nan_policy.SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n_________________ TestStatisticalAnalyzer.test_identical_data __________________\ntests/test_analytics_statistics.py:122: in test_identical_data\n    result = self.analyzer.compare_providers(identical_data, identical_data)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nbench/analytics/statistics.py:54: in compare_providers\n    assumptions = self._check_assumptions(a_scores, b_scores)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nbench/analytics/statistics.py:216: in _check_assumptions\n    _, p_levene = stats.levene(group_a, group_b)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.venv/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:579: in axis_nan_policy_wrapper\n    res = hypotest_fun_out(*samples, **kwds)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.venv/lib/python3.12/site-packages/scipy/stats/_morestats.py:3104: in levene\n    W = numer / denom\n        ^^^^^^^^^^^^^\nE   RuntimeWarning: invalid value encountered in scalar divide\n================================ tests coverage ================================\n_______________ coverage: platform darwin, python 3.12.6-final-0 _______________\n\nName                                     Stmts   Miss  Cover   Missing\n----------------------------------------------------------------------\nbench/__init__.py                            4      0   100%\nbench/adapters/__init__.py                  51     51     0%   7-138\nbench/adapters/base.py                      47     47     0%   7-158\nbench/adapters/chatgpt.py                   60     60     0%   7-187\nbench/adapters/chatgpt_manual.py           176    176     0%   7-476\nbench/adapters/copilot_manual.py           158    158     0%   7-457\nbench/analytics/__init__.py                  5      0   100%\nbench/analytics/insights.py                173    140    19%   32-36, 44-71, 75-167, 171-232, 236-280, 284-378, 382-414, 418-432, 436-450, 454-469, 473, 477-495, 499-501\nbench/analytics/regression.py              136    108    21%   32-39, 47-96, 109-152, 156-166, 176-192, 215-222, 226-238, 246-274, 290-306, 310-319\nbench/analytics/statistics.py              178     70    61%   66, 74-90, 107-136, 183-192, 208-209, 251-253, 269, 316-336, 340-353, 357, 376-393, 398, 400, 402\nbench/analytics/trends.py                  170    127    25%   43, 51-85, 103-126, 134-155, 164-165, 170-195, 199-200, 204-207, 212-225, 229-251, 261-285, 290-299, 303-316, 320-328, 332-342\nbench/cli.py                                16     16     0%   3-28\nbench/core/__init__.py                       2      2     0%   7-14\nbench/core/evaluators/__init__.py           31     31     0%   7-88\nbench/core/evaluators/base.py               46     46     0%   7-121\nbench/core/evaluators/deep_research.py     197    197     0%   7-421\nbench/core/evaluators/exec_summary.py      129    129     0%   7-325\nbench/core/evaluators/metrics_csv.py       109    109     0%   7-255\nbench/core/evaluators/regex_match.py       113    113     0%   7-317\nbench/core/report_utils.py                 128    128     0%   7-269\nbench/core/reporting.py                    339    339     0%   7-724\nbench/core/runner.py                       316    316     0%   7-845\nbench/core/scoring.py                      267    267     0%   7-564\nbench/core/utils.py                         98     98     0%   7-329\nbench/core/validators.py                   169    169     0%   7-491\nbench/tests/__init__.py                      1      1     0%   7\nbench/tests/offline/__init__.py              1      1     0%   6\nbench/tests/online/__init__.py               1      1     0%   6\nbench/web/__init__.py                        2      2     0%   3-5\nbench/web/app.py                           156    156     0%   3-425\n----------------------------------------------------------------------\nTOTAL                                     3279   3058     7%\nCoverage HTML written to dir htmlcov\nCoverage XML written to file coverage.xml\nCoverage JSON written to file coverage.json\n============================= slowest 10 durations =============================\n0.05s call     tests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_compare_providers_auto_selection\n0.04s call     tests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_compare_providers_mannwhitney\n\n(8 durations < 0.005s hidden.  Use -vv to show these durations.)\n=========================== short test summary info ============================\nFAILED tests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_empty_data_handling\nFAILED tests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_identical_data\n========================= 2 failed, 8 passed in 3.33s ==========================\n",
      "stderr": "",
      "duration": 3.33,
      "test_count": 10,
      "failures": [
        "FAILED tests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_empty_data_handling",
        "FAILED tests/test_analytics_statistics.py::TestStatisticalAnalyzer::test_identical_data"
      ],
      "critical_failures": 0
    },
    "integration": {
      "status": "failed",
      "exit_code": 1,
      "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.12.6, pytest-8.4.1, pluggy-1.6.0 -- /Users/drapp/dev/assistEval/.venv/bin/python\ncachedir: .pytest_cache\nrootdir: /Users/drapp/dev/assistEval\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, cov-6.2.1\ncollecting ... collected 13 items\n\ntests/test_qa_integration.py::TestAnalyticsIntegration::test_end_to_end_analytics_pipeline PASSED [  7%]\ntests/test_qa_integration.py::TestAnalyticsIntegration::test_cross_component_data_consistency PASSED [ 15%]\ntests/test_qa_integration.py::TestAnalyticsIntegration::test_error_propagation_handling PASSED [ 23%]\ntests/test_qa_integration.py::TestWebIntegration::test_api_analytics_integration PASSED [ 30%]\ntests/test_qa_integration.py::TestWebIntegration::test_api_parameter_integration PASSED [ 38%]\ntests/test_qa_integration.py::TestWebIntegration::test_concurrent_api_analytics_integration PASSED [ 46%]\ntests/test_qa_integration.py::TestDataIntegrity::test_data_type_consistency FAILED [ 53%]\ntests/test_qa_integration.py::TestDataIntegrity::test_timestamp_handling_consistency PASSED [ 61%]\ntests/test_qa_integration.py::TestDataIntegrity::test_score_range_validation FAILED [ 69%]\ntests/test_qa_integration.py::TestDataIntegrity::test_configuration_consistency PASSED [ 76%]\ntests/test_qa_integration.py::TestSystemResilience::test_memory_cleanup PASSED [ 84%]\ntests/test_qa_integration.py::TestSystemResilience::test_exception_recovery FAILED [ 92%]\ntests/test_qa_integration.py::TestSystemResilience::test_concurrent_operation_safety PASSED [100%]\n\n=================================== FAILURES ===================================\n_________________ TestDataIntegrity.test_data_type_consistency _________________\ntests/test_qa_integration.py:277: in test_data_type_consistency\n    from bench.analytics.trends import TrendResult\nE   ImportError: cannot import name 'TrendResult' from 'bench.analytics.trends' (/Users/drapp/dev/assistEval/bench/analytics/trends.py)\n________________ TestDataIntegrity.test_score_range_validation _________________\ntests/test_qa_integration.py:339: in test_score_range_validation\n    result = analyzer.compare_providers(scores, [0.5, 0.6, 0.7])\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nbench/analytics/statistics.py:62: in compare_providers\n    return self._perform_t_test(a_scores, b_scores, assumptions)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nbench/analytics/statistics.py:239: in _perform_t_test\n    statistic, p_value = stats.ttest_ind(group_a, group_b, equal_var=equal_var)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.venv/lib/python3.12/site-packages/scipy/_lib/deprecation.py:234: in inner_f\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n.venv/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:579: in axis_nan_policy_wrapper\n    res = hypotest_fun_out(*samples, **kwds)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.venv/lib/python3.12/site-packages/scipy/stats/_stats_py.py:6803: in ttest_ind\n    v1 = _var(a, axis, ddof=1, xp=xp)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.venv/lib/python3.12/site-packages/scipy/stats/_stats_py.py:1240: in _var\n    var = _moment(x, 2, axis, mean=mean, xp=xp)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.venv/lib/python3.12/site-packages/scipy/stats/_stats_py.py:1222: in _moment\n    a_zero_mean = _demean(a, mean, axis, xp=xp)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n.venv/lib/python3.12/site-packages/scipy/stats/_stats_py.py:1178: in _demean\n    warnings.warn(message, RuntimeWarning, stacklevel=5)\nE   RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n_________________ TestSystemResilience.test_exception_recovery _________________\ntests/test_qa_integration.py:444: in test_exception_recovery\n    result = analyzer.compare_providers(data_a, data_b)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nbench/analytics/statistics.py:54: in compare_providers\n    assumptions = self._check_assumptions(a_scores, b_scores)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nbench/analytics/statistics.py:205: in _check_assumptions\n    _, p_a = stats.shapiro(group_a)\n             ^^^^^^^^^^^^^^^^^^^^^^\n.venv/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:574: in axis_nan_policy_wrapper\n    warnings.warn(too_small_msg, SmallSampleWarning, stacklevel=2)\nE   scipy.stats._axis_nan_policy.SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n================================ tests coverage ================================\n_______________ coverage: platform darwin, python 3.12.6-final-0 _______________\n\nName                                     Stmts   Miss  Cover   Missing\n----------------------------------------------------------------------\nbench/__init__.py                            4      0   100%\nbench/adapters/__init__.py                  51     51     0%   7-138\nbench/adapters/base.py                      47     47     0%   7-158\nbench/adapters/chatgpt.py                   60     60     0%   7-187\nbench/adapters/chatgpt_manual.py           176    176     0%   7-476\nbench/adapters/copilot_manual.py           158    158     0%   7-457\nbench/analytics/__init__.py                  5      0   100%\nbench/analytics/insights.py                173     10    94%   47, 92, 119, 329, 355, 397, 473, 478, 484, 491\nbench/analytics/regression.py              136     52    62%   78-79, 116, 123, 130, 138, 141, 144, 216, 218, 220, 227, 234-236, 246-274, 290-306, 310-319\nbench/analytics/statistics.py              178     49    72%   66, 74-90, 130, 132, 183-192, 251-253, 316-336, 340-353, 357, 376-393\nbench/analytics/trends.py                  170     38    78%   52, 104, 113-126, 134-155, 186-187, 206, 221, 303-316, 320-328, 333\nbench/cli.py                                16     16     0%   3-28\nbench/core/__init__.py                       2      2     0%   7-14\nbench/core/evaluators/__init__.py           31     31     0%   7-88\nbench/core/evaluators/base.py               46     46     0%   7-121\nbench/core/evaluators/deep_research.py     197    197     0%   7-421\nbench/core/evaluators/exec_summary.py      129    129     0%   7-325\nbench/core/evaluators/metrics_csv.py       109    109     0%   7-255\nbench/core/evaluators/regex_match.py       113    113     0%   7-317\nbench/core/report_utils.py                 128    128     0%   7-269\nbench/core/reporting.py                    339    339     0%   7-724\nbench/core/runner.py                       316    316     0%   7-845\nbench/core/scoring.py                      267    267     0%   7-564\nbench/core/utils.py                         98     98     0%   7-329\nbench/core/validators.py                   169    169     0%   7-491\nbench/tests/__init__.py                      1      1     0%   7\nbench/tests/offline/__init__.py              1      1     0%   6\nbench/tests/online/__init__.py               1      1     0%   6\nbench/web/__init__.py                        2      0   100%\nbench/web/app.py                           156     67    57%   29, 45, 62-63, 71-116, 154-155, 163-229, 237-287, 312, 323, 371-377, 407, 409\n----------------------------------------------------------------------\nTOTAL                                     3279   2671    19%\nCoverage HTML written to dir htmlcov\nCoverage XML written to file coverage.xml\nCoverage JSON written to file coverage.json\n============================= slowest 10 durations =============================\n2.61s call     tests/test_qa_integration.py::TestWebIntegration::test_api_parameter_integration\n2.10s call     tests/test_qa_integration.py::TestSystemResilience::test_memory_cleanup\n1.79s call     tests/test_qa_integration.py::TestWebIntegration::test_concurrent_api_analytics_integration\n0.57s call     tests/test_qa_integration.py::TestWebIntegration::test_api_analytics_integration\n0.45s call     tests/test_qa_integration.py::TestAnalyticsIntegration::test_end_to_end_analytics_pipeline\n0.11s call     tests/test_qa_integration.py::TestDataIntegrity::test_timestamp_handling_consistency\n0.10s call     tests/test_qa_integration.py::TestAnalyticsIntegration::test_cross_component_data_consistency\n0.08s call     tests/test_qa_integration.py::TestAnalyticsIntegration::test_error_propagation_handling\n0.03s call     tests/test_qa_integration.py::TestSystemResilience::test_concurrent_operation_safety\n0.01s setup    tests/test_qa_integration.py::TestWebIntegration::test_api_analytics_integration\n=========================== short test summary info ============================\nFAILED tests/test_qa_integration.py::TestDataIntegrity::test_data_type_consistency\nFAILED tests/test_qa_integration.py::TestDataIntegrity::test_score_range_validation\nFAILED tests/test_qa_integration.py::TestSystemResilience::test_exception_recovery\n======================== 3 failed, 10 passed in 11.31s =========================\n",
      "stderr": "",
      "duration": 11.31,
      "test_count": 13,
      "failures": [
        "FAILED tests/test_qa_integration.py::TestDataIntegrity::test_data_type_consistency",
        "FAILED tests/test_qa_integration.py::TestDataIntegrity::test_score_range_validation",
        "FAILED tests/test_qa_integration.py::TestSystemResilience::test_exception_recovery"
      ],
      "critical_failures": 1
    }
  },
  "configuration": {
    "test_timeout": 300,
    "parallel_jobs": 4,
    "coverage_threshold": 80.0,
    "performance_threshold": 2.0,
    "memory_threshold": 500
  }
}
