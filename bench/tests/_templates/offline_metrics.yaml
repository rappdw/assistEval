# Template for Offline Metrics Task - CSV Classification Analysis
# Copy this file and customize for your specific metrics calculation test case
#
# This template is for tasks that require calculating classification metrics
# (precision, recall, F1, accuracy, confusion matrix) from CSV data

id: "offline.task_name.metrics_csv"
name: "Task Name â€” Metrics from CSV"
category: "offline"
capability_profile:
  web: "forbidden"    # offline tasks cannot use web
  json_required: true
  retries: 1

prompt:
  system: |
    You are an enterprise assistant. Follow instructions exactly. Do not browse the web.
    Do not fabricate sources. Respond only in valid JSON format.
  user: |
    Analyze the following CSV data and calculate classification metrics for [CLASSIFICATION_TASK].

    CSV Data:
    [INSERT_CSV_DATA_HERE]
    # Example:
    # email_id,feature1,feature2,feature3,is_target
    # 1,value1,value2,value3,1
    # 2,value1,value2,value3,0
    # ...

    The last column '[TARGET_COLUMN]' indicates the ground truth (1=positive, 0=negative).

    Calculate the following classification metrics and return them in JSON format:
    - precision (4 decimal places)
    - recall (4 decimal places)
    - f1 (4 decimal places)
    - accuracy (4 decimal places)
    - confusion_matrix with tp, fp, fn, tn (integers)

    Required JSON format:
    {
      "task1_data_metrics": {
        "precision": 0.0000,
        "recall": 0.0000,
        "f1": 0.0000,
        "accuracy": 0.0000,
        "confusion_matrix": {
          "tp": 0,
          "fp": 0,
          "fn": 0,
          "tn": 0
        }
      }
    }

expectation:
  schema_name: "task1_metrics"
  fields:
    - path: "$.task1_data_metrics.precision"
      type: "number"
    - path: "$.task1_data_metrics.recall"
      type: "number"
    - path: "$.task1_data_metrics.f1"
      type: "number"
    - path: "$.task1_data_metrics.accuracy"
      type: "number"
    - path: "$.task1_data_metrics.confusion_matrix.tp"
      type: "integer"
    - path: "$.task1_data_metrics.confusion_matrix.fp"
      type: "integer"
    - path: "$.task1_data_metrics.confusion_matrix.fn"
      type: "integer"
    - path: "$.task1_data_metrics.confusion_matrix.tn"
      type: "integer"

scoring:
  evaluator: "metrics_csv"
  config:
    tolerance: 0.0005        # Numeric tolerance for floating point comparison
    round_to: 4              # Round to 4 decimal places
    weights:
      precision: 6           # Points for precision metric
      recall: 6              # Points for recall metric
      f1: 6                  # Points for F1 score
      accuracy: 6            # Points for accuracy metric
      confusion_matrix:      # Points for confusion matrix components
        tp: 3                # True positives
        fp: 3                # False positives
        fn: 3                # False negatives
        tn: 3                # True negatives

fixtures:
  - path: "fixtures/csv/[YOUR_CSV_FILE].csv"
    variable: "csv_content"

answer_key: "answer_keys/offline/[YOUR_TASK]_metrics.json"

# Instructions for customization:
# 1. Replace [CLASSIFICATION_TASK] with your specific task description
# 2. Replace [INSERT_CSV_DATA_HERE] with your actual CSV data
# 3. Replace [TARGET_COLUMN] with your ground truth column name
# 4. Replace [YOUR_CSV_FILE] with your fixture filename
# 5. Replace [YOUR_TASK] with your task identifier
# 6. Create corresponding answer key JSON file with expected metrics
# 7. Adjust weights if needed (should total to your desired points)
